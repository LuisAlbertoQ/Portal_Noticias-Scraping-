# ğŸ“° Web Scraping Django - Portal de Noticias El Comercio

Un sistema completo de **web scraping** desarrollado en Django para extraer, almacenar y mostrar noticias del periÃ³dico **El Comercio** (PerÃº) de manera automatizada. El proyecto incluye una interfaz web moderna para visualizar noticias por categorÃ­as con filtros avanzados y funcionalidades de bÃºsqueda.

## ğŸ¯ Â¿De quÃ© trata el proyecto?

Este proyecto es un **agregador de noticias inteligente** que:

- **Extrae automÃ¡ticamente** noticias de El Comercio usando web scraping
- **Categoriza las noticias** en: PolÃ­tica, EconomÃ­a, Mundo, TecnologÃ­a
- **Almacena** tÃ­tulos, autores, fechas, imÃ¡genes y enlaces en base de datos
- **Presenta** las noticias en una interfaz web moderna y responsive
- **Ejecuta scraping** manual o programado por categorÃ­as especÃ­ficas

## ğŸ› ï¸ TecnologÃ­as Utilizadas

### Backend
- **Django 5.2.6** - Framework web principal
- **Python 3.13** - Lenguaje de programaciÃ³n
- **MySQL** - Base de datos (mysqlclient)
- **Playwright** - AutomatizaciÃ³n de navegadores para scraping
- **BeautifulSoup4** - Parsing y extracciÃ³n de datos HTML
- **Celery** - Tareas asÃ­ncronas (opcional)

### Frontend
- **HTML5/CSS3** - Interfaz de usuario
- **JavaScript** - Interactividad
- **Font Awesome** - IconografÃ­a
- **CSS Grid/Flexbox** - Layout responsive

### Herramientas de Desarrollo
- **Git** - Control de versiones
- **Virtual Environment** - Aislamiento de dependencias
- **Django Management Commands** - Comandos personalizados

## ğŸ“‹ Requisitos del Sistema

- **Python 3.13** o superior
- **pip** (gestor de paquetes de Python)
- **Git** (para clonar el repositorio)
- **MySQL** (base de datos)
- **Navegador web** (Chrome/Firefox para Playwright)

## ğŸš€ GuÃ­a de InstalaciÃ³n Completa

### Paso 1: Clonar el Repositorio
`ash
git clone <URL_DEL_REPOSITORIO>
cd web_Scraping
`

### Paso 2: Crear Entorno Virtual
`ash
# Windows (PowerShell)
python -m venv env
.\env\Scripts\Activate.ps1

# Windows (CMD)
python -m venv env
.\env\Scripts\activate.bat

# Linux/Mac
python -m venv env
source env/bin/activate
`

### Paso 3: Instalar Dependencias
`ash
pip install -r requirements.txt
`

### Paso 4: Instalar Navegadores de Playwright
`ash
playwright install
`

### Paso 5: Configurar Base de Datos

1. **Crear base de datos MySQL:**
   `sql
   CREATE DATABASE web_scraping_db;
   `

2. **Configurar settings.py** (si es necesario):
   `python
   DATABASES = {
       'default': {
           'ENGINE': 'django.db.backends.mysql',
           'NAME': 'web_scraping_db',
           'USER': 'tu_usuario',
           'PASSWORD': 'tu_contraseÃ±a',
           'HOST': 'localhost',
           'PORT': '3306',
       }
   }
   `

### Paso 6: Ejecutar Migraciones
`ash
python manage.py migrate
`

### Paso 7: Crear Superusuario (Opcional)
`ash
python manage.py createsuperuser
`

### Paso 8: Iniciar Servidor
`ash
python manage.py runserver
`

### Paso 9: Acceder a la AplicaciÃ³n
Abre tu navegador y ve a: **http://127.0.0.1:8000/**

## ğŸ“– CÃ³mo Usar el Sistema

### 1. Visualizar Noticias
- **PÃ¡gina principal**: Todas las noticias
- **CategorÃ­as especÃ­ficas**: /politica, /economia, /mundo, /tecnologia

### 2. Filtrar Contenido
- **Por fecha**: Hoy, Ãºltima semana, Ãºltimo mes
- **Por imÃ¡genes**: Solo noticias con imÃ¡genes
- **BÃºsqueda**: Buscar por tÃ­tulo o autor

### 3. Ejecutar Scraping
- **BotÃ³n "Scraping"** en cada pÃ¡gina para extraer noticias
- **Comandos manuales**:
   `ash
   python manage.py scrape_elcomercio        # Todas las noticias
   python manage.py scrape_elcomercio_pol    # Solo polÃ­tica
   python manage.py scrape_economia          # Solo economÃ­a
   python manage.py scrape_mundo             # Solo mundo
   python manage.py scrape_tecnologia        # Solo tecnologÃ­a
   `

## ï¿½ï¿½ Estructura del Proyecto

`
web_Scraping/
â”œâ”€â”€ ï¿½ï¿½ scraping/                    # App principal
â”‚   â”œâ”€â”€ ğŸ“„ models.py               # Modelo de datos (Noticia)
â”‚   â”œâ”€â”€ ğŸ“„ views.py                # Vistas para cada categorÃ­a
â”‚   â”œâ”€â”€ ğŸ“„ urls.py                 # Rutas de la aplicaciÃ³n
â”‚   â”œâ”€â”€ ğŸ“ management/commands/    # Comandos de scraping
â”‚   â”‚   â”œâ”€â”€ scrape_elcomercio.py
â”‚   â”‚   â”œâ”€â”€ scrape_elcomercio_pol.py
â”‚   â”‚   â”œâ”€â”€ scrape_economia.py
â”‚   â”‚   â”œâ”€â”€ scrape_mundo.py
â”‚   â”‚   â””â”€â”€ scrape_tecnologia.py
â”‚   â”œâ”€â”€ ğŸ“ templates/noticias/     # Plantillas HTML
â”‚   â”‚   â”œâ”€â”€ lista.html
â”‚   â”‚   â”œâ”€â”€ politica.html
â”‚   â”‚   â”œâ”€â”€ economia.html
â”‚   â”‚   â”œâ”€â”€ mundo.html
â”‚   â”‚   â””â”€â”€ tecnologia.html
â”‚   â””â”€â”€ ğŸ“ static/css/            # Estilos CSS
â”‚       â””â”€â”€ noticias.css
â”œâ”€â”€ ğŸ“ web_scraping/              # ConfiguraciÃ³n Django
â”‚   â”œâ”€â”€ settings.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â””â”€â”€ wsgi.py
â”œâ”€â”€ ğŸ“„ manage.py                  # Script de gestiÃ³n Django
â”œâ”€â”€ ğŸ“„ requirements.txt           # Dependencias Python
â””â”€â”€ ğŸ“„ README.md                  # Este archivo
`

## ğŸ”§ Comandos Ãštiles

### Desarrollo
`ash
# Iniciar servidor de desarrollo
python manage.py runserver

# Crear migraciones
python manage.py makemigrations

# Aplicar migraciones
python manage.py migrate

# Acceder al shell de Django
python manage.py shell
`

### Scraping
`ash
# Scraping completo
python manage.py scrape_elcomercio

# Scraping por categorÃ­a
python manage.py scrape_elcomercio_pol
python manage.py scrape_economia
python manage.py scrape_mundo
python manage.py scrape_tecnologia
`

### Base de Datos
`ash
# Ver estado de migraciones
python manage.py showmigrations

# Resetear base de datos (Â¡CUIDADO!)
python manage.py flush
`

## âš™ï¸ ConfiguraciÃ³n Avanzada

### Variables de Entorno (Opcional)
Crea un archivo .env en la raÃ­z del proyecto:
`nv
SECRET_KEY=tu_clave_secreta_aqui
DEBUG=True
DATABASE_URL=mysql://usuario:password@localhost:3306/web_scraping_db
`

### Celery para Tareas AsÃ­ncronas
`ash
# Instalar Redis (requerido para Celery)
# Windows: Descargar de https://redis.io/download
# Linux: sudo apt-get install redis-server

# Ejecutar worker de Celery
celery -A web_scraping worker --loglevel=info
`

## ğŸ› SoluciÃ³n de Problemas

### Error de Playwright
`ash
# Reinstalar navegadores
playwright install --force
`

### Error de Base de Datos
`ash
# Verificar conexiÃ³n MySQL
python manage.py dbshell
`

### Error de Dependencias
`ash
# Reinstalar dependencias
pip install -r requirements.txt --force-reinstall
`

## ğŸ“Š CaracterÃ­sticas del Sistema

- âœ… **Scraping inteligente** con detecciÃ³n automÃ¡tica de imÃ¡genes
- âœ… **Interfaz responsive** con diseÃ±o moderno
- âœ… **Filtros avanzados** por fecha, categorÃ­a y contenido
- âœ… **BÃºsqueda en tiempo real** por tÃ­tulo y autor
- âœ… **EstadÃ­sticas automÃ¡ticas** de noticias
- âœ… **Manejo de errores** robusto
- âœ… **OptimizaciÃ³n de imÃ¡genes** automÃ¡tica
- âœ… **NavegaciÃ³n por categorÃ­as** intuitiva

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (git checkout -b feature/AmazingFeature)
3. Commit tus cambios (git commit -m "Add some AmazingFeature")
4. Push a la rama (git push origin feature/AmazingFeature)
5. Abre un Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ‘¨â€ğŸ’» Autor

- **Tu Nombre** - [@tuusuario](https://github.com/tuusuario)

## ğŸ“ Soporte

Si tienes problemas o preguntas:
- Abre un [Issue](https://github.com/tuusuario/web_Scraping/issues)
- Contacta: tu.email@ejemplo.com

---

**Â¡Disfruta scrapeando noticias! ğŸ“°âœ¨**
